# -*- coding:utf-8 -*-

from scrapy.selector import Selector
from scrapy.contrib.linkextractors.sgml import SgmlLinkExtractor
from scrapy.contrib.spiders import CrawlSpider, Rule
from scrapy.http import Request
from ygg_scrapy.items import weiboItem

class WeiboSpider(CrawlSpider):
    name = 'weibo'
    allowed_domains = ['weibo.com']
    start_urls = {
        'http://weibo.cn/1087770692',

    }

    def start_requests(self):



        yield Request('http://weibo.cn', cookies={
            '_T_WM': 'f8850442330a42c8edae9d40b94d4bee',
            'SUB': 'AV7hd8Jg5%2BXixbjCEbl0Efd9%2Bh32kJFYQOhl%2BEsRNkBPcAuzIaVn9gXydIR9CBm28BqirksM%2Fp7pYrGiq7C8O%2FRDF%2F%2Fz4YwCb7WCoKQqIIBK9egjx4%2BnzkkIVs1qzBIwhle7S8mvaMK6sNn%2FLJdVjks%3D',
            'gsid_CTandWM':'4uct80911qy8Oa9lqkpa19rOHbs'
        })

        for url in self.start_urls:

            yield Request(url, callback=self.parse_item, dont_filter=True)

    def parse_item(self, response):

        items = []

        item = weiboItem()

        item['page_source'] = response.body

        items.append(item)

        return items
